Theano currently seems to throw an error when the gradient computation happens....

My own gradient computation would actually be pretty simple.

 DefinedPredOp(Op): compiled out?
 AssignPreimageToVar(Op): dst = columnVector
    grad(dst,w): eye if columnVector==w, 0 else
 AssignZeroToVar(Op): dst = const
    grad(dst,w): zeros
 AssignOnehotToVar(Op): dst = const
    grad(dst,w): zeros
 VecMatMulOp(Op): dst = src * M or dst=src.M^T
    grad(dst,w): grad(src,w)*M + src*grad(M,w)
                 = grad(src,w)*M if M!=w, src if M=w
 ComponentwiseVecMulOp(Op): dst = src1 o src2
                 = grad(dst,w) = grad(src1,w) o src2 + src1 o grad(src2,w) 
 WeightedVec(Op): dst = vec * weighter.sum()
 		 = grad(vec,w) * weighter.sum() + vec * grad(weighter.w).sum()

----------
Minibatches: I should just give up and do the scan in the loss function level
 http://deeplearning.net/software/theano/library/scan.html --- except that gives up on
 using bricks, I guess?

Learning/training:
 - textcat toy w/o incoming chains DONE
 -- data/theory prep DONE
 -- matrixdb wrapper around theano shared variables DONE
 --- db contains a parameterDB sub-object, to which it delegates matrix and matrixpreimage requests
 --- matrixpreimage, matrix requests must include a context, eval or expression
     and returns shared.get_value() or just shared
 --- parameterDB also returns a set of parameters
 -- weighted facts/matrices - not needed yet
 -- trylearn.py following logreg.py example....

 - some KBC task
 - some binary predicate tuning task

Simple TODO's:
 - add a proof_failed constant so I never get a zero vector?
 - verify tensorlog works on matrix input, not just single rows
 - tensorlog CLI
 - cache matrixdb transposes and preimages
 - program.maxdepth parameter
 - test sparsity of theano stuff --- why is it so slow? is it actually dense?
 - scalability test - compare to real prolog?


Bugs:

- p(X,X) isn't handled correctly.  should I split j=0 into (0,'i') and
(0,'o') in the factor graph?  should there actually be 'factors' and
not goals?
 - 

Think thru: 
 - Blocks and Fuel
 - embeddings 
 - unary predicates or binary predicates with a constant (what's the inferred mode for those?)
 - pairs: possibly impossible to do as a gradient.  (note that for classification all I need is
   pair(X,c,Z) which could be done by just constructing the proper matrix in matrixdb),
   or even with pair_with_c(X,Z)
  - oneHot analysis
  - for theano, do envir's need to include some sort of prefix to keep the var namespaces apart?

------------------------------------------------------------------------------
