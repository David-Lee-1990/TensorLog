TODO easy: 

 - clean up cora example - make demo? check deeper programs?
 - add royal family data - with all rules
 - simple.Compiler().[de]serialize? that would serialize a program as well as a DB
 should decide how to have this interact with session, set_all_db_params_to_learned_values, etc
 - new command: simple serialize --input x --output y
 - comline to gflags?

TODO major:

 - multi-task datasets: test one
 - extensions (to matrixDB? in dbschema? in simple? in new package?) to preprocess matrices
  -- tfidf weighting: 
  -- cm-embedding:
  --- create matrices that embed a type, or convert a matrix from types to embedded types
  --- use plugins to de-embed a type

 - general tools for debug/explanation?
 -- current: given input, function --> outputs
 -- drill down: given input, function, given output + intermediate proof variable --> values intermediate variable takes on
 -- drill down: given input, function, given output + given intermediate variable1,var2 ... varK-1 + varK --> values intermediate variable varK takes on
 -- drill down by modifying the program....

 - scheme for adding tensorboard summaries somehow, for debugging
 -- maybe scope graph nodes with rule names/ids?
 -- maybe include api for specifying summaries to add to rules or database predicates?
 - alternative to calling out to tensorlog would be to
 iteratively process multiple-input, single-output plugins.
 for i in plugInGoalPositions:
   compile opsequence for A<=B1,...,B[i-1]
   add op to compute output of B[i] from input
   syntactic rule: links in polytree cannot cross boundaries
    defined by plugin literals
- having multiple inputs in bpcompiler would also be nice....
 hard would this be to do?

 - autoset_db_params: schema predicates can be marked 'trainable' when you
 declare their types, OR will be automarked if they appear after a //
 - tlog(autoset_db_params=True) will only set UNDEFINED params
 - you can load just parameters, not a whole DB



NATIVE:
 - check y - p vs p - y in tensorlog (and gradient sign)
 - check family dataset
 - check subfunction reuse in grid
 - add __repr__ functions for learners so you can echo them in expt
 - cleanup gradient stuff:
 -- plearn tasks should postprocess the parameters via rowsum for the paramGrad weights - sort of like a combiner
 -- plearn postprocessing should do weighted average of the gradients - maybe do with with a bunch of pairwise addition tasks?
 - need to test Adagrad on real data
   - update: regularization runs but it possibly broken

NATIVE CLEANUPS: see Cleanup-notes.txt

TUTORIAL/DOCS

  see wiki

BUGS: 

 - head p(X,X) doesn't work

DESIGN FLAWS: 1 fails but 2 is ok even tho both are polytrees.

 1 p(X,Y) :- q(X,X1),r(Y,Y1),s(X1,Y1)
 2 p(X,Y) :- q(X,X1),s(X1,Y1),r(Y,Y1)

This is actually a problem for the royal-family task.  I guess I can
do this with a reordering step in bpcompiler but that seems sort of
kludgy....for new ordering, you could repeatedly scan forward to find
the first rhs literal that's allowable? or .... have queue of
disallowed literals that you build up, and insert them whenever their
inputs are ready.

You can always do this manually if predicates are called in a single
mode, of course.

USE CASES FOR TF/TLOG interface:

 -- training from partial information, known pos and known negatives (try this out!)
 --- define two prediction predicates: predict(X,Y) and predictComplement(X,Y)
 --- data for predict is known pos, for predictComplement, known neg
 set up optimization as follows:
   shared_input = tf.PlaceHolder(....)
   f1 = tlog.inference("predict/io", input=shared_input)
   f2 = tlog.inference("predictComplement/io", input=shared_input)
   loss = tlog.loss("predict/io") - tlog.loss("predictComplement/io")
   ...
 -- learn conjunction of properties (try this out!)
   answer1(Q,Y) <= mention(Q,EC), entity(EC,E), chain1(E,Y) // (w1(F) | context(EC,C), feature(C,F))
   answer2(...) <= ...
   shared_input = tf.PlaceHolder(....)   
   f1 = tlog.inference("answer1/io", input=shared_input)
   f2 = tlog.inference("answer2/io", input=shared_input)
   ...
   f = f1 * ... * fk
   loss = tlog.loss_for("answer/io", inference=f, input=shared_input, target_output=...)

--------------------
  def _softmaxFun2Expr(self,subExpr,typeName):
    if xcomp.conf.softmax_alg == 'dense':
      # zeros are actually big numbers for the softmax,
      # so replace them with a big negative number
      subExprReplacing0WithNeg10 = tf.where(
          subExpr>0.0,
          subExpr,
          tf.ones(tf.shape(subExpr), tf.float32)*(-10.0))
      return tf.nn.softmax(subExprReplacing0WithNeg10 + self._nullSmoother[typeName])
    elif xcomp.conf.softmax_alg == 'sparse':
      # inference is ok but the gradients aren't there....problem is this use of 'where', it seems
      smoothedSubexpr = subExpr + self._nullSmoother[typeName]
      nz_indices = tf.where(tf.not_equal(smoothedSubexpr, tf.constant(0, dtype=tf.float32)))
      nz_values = tf.gather_nd(smoothedSubexpr, nz_indices)
      sparseSubexpr = tf.SparseTensor(nz_indices, nz_values, tf.cast(tf.shape(smoothedSubexpr),tf.int64))
      sparseSoftmax = tf.sparse_softmax(sparseSubexpr)
      denseSoftmax = tf.sparse_tensor_to_dense(sparseSoftmax)
      return denseSoftmax
    else:
      assert False
